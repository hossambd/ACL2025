# Implicit Hate Target Span Identification in Zero- and Few-Shot Settings with Selective Sub-Billion Parameter Models 

**ACL 2025**  ğŸ§ 
*Hossam Boudraa, Benoit Favre, Raquel Urena*

---

## ğŸ” Overview

This repository provides the code, prompts, and benchmark results for identifying **implicit hate speech target spans** using **parameter-efficient masked and generative SLMs (<1B)** in zero-shot, few-shot, and supervised settings.

Implicit hate speech poses a unique challenge as it relies on **contextual, euphemistic, and ideologically coded expressions** rather than explicit slurs. Our work evaluates span-level models across multiple datasets to address this problem with interpretable, efficient, and instruction-tuned architectures.

---

## ğŸ§ª Key Contributions

âœ… A benchmark for **Implicit Target Span Identification (iTSI)** using **SBIC**, **IHC**, and **OffensiveLang** datasets.  
âœ… Performance comparison of multiple sub-1B models in **zero-shot**, **few-shot**, and **fully supervised** conditions.  
âœ… Introduction of **instruction tuning and LoRA fine-tuning** to enhance detection sensitivity.  
âœ… In-depth **error analysis via LDA topic modeling** to reveal systematic model blind spots.  
âœ… Demonstration that **scale isnâ€™t everything**: small, well-instructed models can outperform larger LLMs.

---

## ğŸ“Š Results Summary

| Model                  | Params | IHC F1 | SBIC F1 |
|------------------------|--------|--------|---------|
| RoBERTa-Large          | 355M   | 72.5   | 75.8    |
| ModernBERT             | 125M   | 72.2   | 75.1    |
| LLaMA 3.2 (Instruct)   | 1B     | 68.5   | 72.5    |
| SmolLM2-135M (Instruct)| 135M   | 66.0   | 69.8    |

- **Few-shot F1 (10 examples):** 68.2 (SBIC), 64.0 (IHC)  
- **LoRA Rank 16 fine-tuning:** nearly matches full-data fine-tuning with 75% less compute time.

---

## ğŸ“ Datasets

| Dataset         | Description                                                                 |
|----------------|-----------------------------------------------------------------------------|
| **SBIC**        | Social Bias Inference Corpus: 34k implicit bias examples (span-annotated via GPT). |
| **IHC**         | Implicit Hate Corpus: 6,300 tweets with implicit hate.                      |
| **OffensiveLang** | Synthetic ChatGPT-based utterances with human-verified span annotations.   |

Annotation strategy: Weak supervision + automatic annotation (GPT-3.5) for span labels.

---

## ğŸ’¡ Research Questions

- ğŸ”¬ Does increasing model size improve implicit hate span detection?
- âš™ï¸ Does instruction-tuning help?
- ğŸ§ª Is few-shot fine-tuning competitive?
- ğŸ§µ What can topic-based error analysis reveal?

---

## ğŸ› ï¸ Setup & Training

### Requirements
```bash
pip install torch transformers scikit-learn datasets
```

### Fine-tuning with LoRA (example)
```bash
python train.py \
  --model_name SmolLM2-135M-Instruct \
  --dataset SBIC \
  --tuning lora \
  --lora_r 16 \
  --epochs 40 \
  --lr 1e-2 \
  --batch_size 16
```

### Inference (Zero-Shot with Prompting)
```bash
python zero_shot_infer.py \
  --model llama-3.2-1B-Instruct \
  --prompt_template templates/itsi_prompt.txt \
  --dataset IHC
```

## ğŸ§µ Error Analysis

- LDA-based topic modeling reveals common failure themes:  
  *gender discourse*, *political ideology*, *identity framing*.  
- Many false negatives involve **sarcasm**, **euphemisms**, or **ideologically subtle cues**.


## ğŸ§‘â€ğŸ’» Contact

`hossam.boudraa@etu.univ-amu.fr`  â€“ [@hossambd](https://github.com/hossambd)  
